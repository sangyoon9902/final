# server/rag/query_engine_kspo_only.py
from __future__ import annotations
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path
import os, json, re

import httpx
from dotenv import load_dotenv
from openai import OpenAI

# 1) CSV kNN
from .query_engine_csv import retrieve_similar_structured
# 2) CSV ë¹ˆë„ â†’ KSPO ë§¤ì¹­/ëŒ€í‘œì˜ìƒ ì„ íƒ(ì¹´í…Œê³ ë¦¬: ì‹¬íì§€êµ¬ë ¥/ê·¼ë ¥Â·ê·¼ì§€êµ¬ë ¥/ìœ ì—°ì„±)
from .query_engine_kspo_videos import prescribe_from_freq_and_kspo

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ .env ëª…ì‹œ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€
SERVER_DIR = Path(__file__).resolve().parent.parent  # server/
ENV_PATH = SERVER_DIR / ".env"
load_dotenv(ENV_PATH)

# OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ë³´ì •(ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
_k = (os.getenv("OPENAI_API_KEY") or "").strip()
os.environ["OPENAI_API_KEY"] = _k

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ OpenAI í´ë¼ì´ì–¸íŠ¸: ì§€ì—° ì´ˆê¸°í™”(lazy init) â”€â”€â”€â”€â”€â”€â”€â”€â”€
__openai_client: Optional[OpenAI] = None
def _get_openai_client() -> OpenAI:
    """
    - import ì‹œì ì´ ì•„ë‹ˆë¼ í˜¸ì¶œ ì‹œì ì— ì´ˆê¸°í™”
    - proxiesëŠ” httpx.Clientë¥¼ í†µí•´ ì„¤ì • (OpenAI(...)ì— proxies ì¸ì ì§ì ‘ ì „ë‹¬ ê¸ˆì§€)
    """
    global __openai_client
    if __openai_client is not None:
        return __openai_client

    api_key = (os.getenv("OPENAI_API_KEY") or "").strip()
    base_url = (os.getenv("OPENAI_BASE_URL") or "").strip() or None
    org_id   = (os.getenv("OPENAI_ORG_ID") or "").strip() or None

    proxy = os.getenv("HTTPS_PROXY") or os.getenv("HTTP_PROXY")
    http_client = httpx.Client(proxies=proxy, timeout=30.0) if proxy else None

    __openai_client = OpenAI(
        api_key=api_key,
        base_url=base_url,
        organization=org_id if org_id else None,
        http_client=http_client,
    )
    return __openai_client


VALID_CATS = ["ì‹¬íì§€êµ¬ë ¥", "ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥", "ìœ ì—°ì„±"]

def _score_of(n: Dict[str, Any]) -> float:
    return float(n.get("combined_score") or n.get("raw_score") or n.get("score") or 0.0)

def _kspo_meta_path() -> str:
    return str(Path(__file__).resolve().parent / "embed_store" / "kspo_videos" / "kspo_meta.json")

def _acsm_meta_path() -> str:
    return str(Path(__file__).resolve().parent / "embed_store" / "acsm6" / "acsm6_meta.json")

# âœ… ì •í™• ë¼ë²¨ ì§‘í•©
AGE_BANDS = ["ìœ ì•„ê¸°", "ìœ ì†Œë…„", "ì²­ì†Œë…„", "ì„±ì¸", "ì–´ë¥´ì‹ "]

# âœ… alias â†’ ì •í™• ë¼ë²¨
_AGE_ALIASES = {
    "ìœ ì•„ê¸°": "ìœ ì•„ê¸°", "ìœ ì•„": "ìœ ì•„ê¸°",
    "ìœ ì†Œë…„ê¸°": "ìœ ì†Œë…„", "ìœ ì†Œë…„": "ìœ ì†Œë…„",
    "ì²­ì†Œë…„ê¸°": "ì²­ì†Œë…„", "ì²­ì†Œë…„": "ì²­ì†Œë…„",
    "ì„±ì¸ê¸°": "ì„±ì¸", "ì„±ì¸": "ì„±ì¸",
    "ì–´ë¥´ì‹ ê¸°": "ì–´ë¥´ì‹ ", "ì–´ë¥´ì‹ ": "ì–´ë¥´ì‹ ", "ë…¸ì¸": "ì–´ë¥´ì‹ ", "ê³ ë ¹": "ì–´ë¥´ì‹ ",
}

def _norm_title(s: str) -> str:
    if not s: return ""
    s = re.sub(r"\([^)]*\)", " ", s)
    s = re.sub(r"\[[^\]]*\]", " ", s)
    s = re.sub(r"[Â·â€¢\-:_/]+", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s.lower()

def _canon_age_label(tok: str) -> Optional[str]:
    tok = (tok or "").strip()
    if tok in AGE_BANDS:
        return tok
    return _AGE_ALIASES.get(tok)

def _age_band_from_age(age: Optional[int]) -> str:
    try:
        a = int(age)
    except Exception:
        return "ì„±ì¸"
    if a <= 6:   return "ìœ ì•„ê¸°"
    if a <= 12:  return "ìœ ì†Œë…„"
    if a <= 18:  return "ì²­ì†Œë…„"
    if a <= 64:  return "ì„±ì¸"
    return "ì–´ë¥´ì‹ "

def _band_distance(a: str, b: str) -> int:
    try:
        ia = AGE_BANDS.index(a); ib = AGE_BANDS.index(b)
        return abs(ia - ib)
    except ValueError:
        return 3

def _split_targets(s: str) -> List[str]:
    if not s: return []
    # ê´„í˜¸ ì•ˆ ë²”ìœ„(ì˜ˆ: 19~64ì„¸) ì œê±°
    s = re.sub(r"\([^)]*\)", "", s)
    parts = re.split(r"[\/,\s|Â·]+", s.strip())
    out: List[str] = []
    for p in parts:
        canon = _canon_age_label(p)
        if canon and canon not in out:
            out.append(canon)
    return out

def _rerank_video_by_age_and_target(
    picked: Optional[Dict[str, Any]],
    *,
    title: str,
    category: str,
    user_age_band: str,
    meta_rows: List[Dict[str, Any]],
) -> Optional[Dict[str, Any]]:
    norm_t = _norm_title(title)
    cands = [
        r for r in meta_rows
        if _norm_title(r.get("title") or "") == norm_t
        and (r.get("fitness_category") or "").strip() == (category or "").strip()
    ]
    if not cands:
        cands = [r for r in meta_rows if _norm_title(r.get("title") or "") == norm_t]
    if not cands:
        return picked

    def score(r: Dict[str, Any]) -> Tuple[int, int, int]:
        targets = _split_targets(r.get("target") or "")
        d = min((_band_distance(user_age_band, t) for t in targets), default=3)
        cat_penalty = 0 if (r.get("fitness_category") or "") == category else 2
        try:
            rank = int(r.get("rank_on_page") or 999)
        except Exception:
            rank = 999
        return (d, cat_penalty, rank)

    cands.sort(key=score)
    best = cands[0]
    if picked and best.get("youtube_id") != picked.get("youtube_id"):
        print(
            f"[KSPO-rerank] '{title}' ({category}) "
            f"user_band={user_age_band} -> {best.get('youtube_id')} "
            f"(target={best.get('target')}, rank={best.get('rank_on_page')})"
        )
    return best

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSV ìœ ì‚¬ì‚¬ë¡€ í…ìŠ¤íŠ¸ì—ì„œ ì¢…ëª© í† í° ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _extract_names_from_csv_neighbors(csv_neighbors: List[Dict[str, Any]]) -> Dict[str, int]:
    bag: Dict[str, int] = {}
    sep_re = re.compile(r"[;,/]| / |Â·|â€¢|\n")
    clean_re = re.compile(r"\s+")
    for n in (csv_neighbors or []):
        text = f"{n.get('prescription_text') or ''} {n.get('prescription') or ''}"
        text = re.sub(r"(ì¤€ë¹„ìš´ë™|ë³¸ìš´ë™|ì •ë¦¬ìš´ë™)\s*:\s*", " ", text)
        parts = [p.strip() for p in sep_re.split(text) if p.strip()]
        for p in parts:
            if any(tok in p for tok in ["ë£¨í‹´í”„ë¡œê·¸ë¨","ë£¨í‹´ ìŠ¤íŠ¸ë ˆì¹­","ë£¨í‹´","í”„ë¡œê·¸ë¨"]):
                continue
            p = re.sub(r"\d+\s*(ì„¸íŠ¸|íšŒ|ë¶„|ì´ˆ|RM|%)", " ", p)
            p = re.sub(r"[()\[\]]", " ", p)
            p = clean_re.sub(" ", p).strip()
            if 1 <= len(p) <= 30:
                bag[p] = bag.get(p, 0) + 1
    return bag

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ACSM6 ê°„ë‹¨ í›„ë³´ ê²€ìƒ‰ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_acsm_meta() -> List[Dict[str, Any]]:
    p = _acsm_meta_path()
    if not os.path.exists(p):
        return []
    try:
        with open(p, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, list):
            return data
        return data.get("items", [])
    except Exception:
        return []

def _match_score(text: str, q_terms: List[str]) -> int:
    s = 0
    tl = text.lower()
    for t in q_terms:
        t = (t or "").lower().strip()
        if not t: continue
        if t in tl: s += 2
    return s

def _mk_terms(payload: Dict[str, Any]) -> List[str]:
    u = payload.get("user") or {}
    m = payload.get("measurements") or {}
    surveys = payload.get("surveys") or {}

    terms = [
        "ìœ ì‚°ì†Œ", "ê·¼ë ¥", "ê·¼ì§€êµ¬ë ¥", "ìœ ì—°ì„±",
        "ë¹ˆë„", "ê°•ë„", "ì‹œê°„", "RPE", "HRR", "1RM", "ì •ì  ìŠ¤íŠ¸ë ˆì¹­",
    ]
    age = u.get("age")
    sex = (u.get("sex") or "").upper()
    if isinstance(age, (int, float)):
        if age >= 65: terms += ["ê³ ë ¹ì", "ë…¸ì¸", "ë‚™ìƒ", "ê· í˜•"]
        elif age <= 18: terms += ["ì²­ì†Œë…„", "ì†Œì•„"]
    if sex in ("F","M"): terms.append(f"ì„±ë³„:{sex}")

    if m.get("situp_reps") is not None: terms += ["ë³µê·¼", "ì²´ê°„", "ì½”ì–´"]
    if m.get("reach_cm") is not None: terms += ["ì¢Œì „êµ´", "í–„ìŠ¤íŠ¸ë§", "ìœ ì—°ì„±"]
    if m.get("step_vo2max") is not None: terms += ["VO2max", "ì‹¬í", "ì¤‘ê°•ë„", "ê³ ê°•ë„"]

    risk_flags = []
    s1 = (surveys.get("survey1") or {})
    if s1.get("high_risk") is True: risk_flags.append("parq_high_risk")
    s4 = (surveys.get("survey4") or {})
    if s4.get("frailty_flag") is True: risk_flags.append("frailty_flag")
    if risk_flags:
        terms += ["ì•ˆì „", "ê¸ˆê¸°", "ëª¨ë‹ˆí„°ë§", "ê³ ìœ„í—˜", "ì˜í•™ì  í‰ê°€"]

    return list(dict.fromkeys(terms))

def retrieve_acsm_candidates(payload: Dict[str, Any], top_k: int = 8) -> List[Dict[str, Any]]:
    meta = _load_acsm_meta()
    if not meta:
        return []
    terms = _mk_terms(payload)
    scored: List[Tuple[int, Dict[str, Any]]] = []
    for it in meta:
        text = " ".join([
            it.get("title") or "",
            " ".join(it.get("keywords") or []),
            it.get("excerpt") or ""
        ])
        s = _match_score(text, terms)
        if s > 0:
            scored.append((s, it))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [it for _, it in scored[:top_k]]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒíƒœ ë¦¬í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE = Path(__file__).resolve().parent
def rag_status() -> Dict[str, Any]:
    structured_store = BASE / "embed_store" / "csv"
    kspo_store = BASE / "embed_store" / "kspo_videos"
    acsm_store = BASE / "embed_store" / "acsm6"
    return {
        "csv_structured_files": {
            "index": (structured_store / "faiss_structured.index").exists(),
            "pipeline": (structured_store / "structured_pipeline.joblib").exists(),
            "meta": (structured_store / "structured_meta.json").exists(),
        },
        "kspo_video_files": {
            "meta": (kspo_store / "kspo_meta.json").exists(),
        },
        "acsm6_files": {
            "meta": (acsm_store / "acsm6_meta.json").exists(),
        },
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ KSPO ìœ í˜•(T) & í—¤ë” ê³ ì • í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _type_line_for_category(cat: str, kspo_plan: Dict[str, Any], max_names: int = 2) -> str:
    freq_map = (kspo_plan.get("top_per_category", {}) or {}).get(cat) or {}
    top_names = list(freq_map.keys())[:max_names]
    v = (kspo_plan.get("videos", {}) or {}).get(cat) or {}
    vtitle = v.get("title") or "(ëŒ€í‘œì˜ìƒ ì—†ìŒ)"
    vyoutube = v.get("youtube_url") or ""
    names = ", ".join(top_names) if top_names else "(CSV ê·¼ê±° ë¶€ì¡±)"
    if vyoutube:
        return f"{names} Â· ëŒ€í‘œì˜ìƒ: {vtitle} (YouTube: {vyoutube})"
    return f"{names} Â· ëŒ€í‘œì˜ìƒ: {vtitle}"

def _head_line_for_category(cat: str, kspo_plan: Dict[str, Any]) -> str:
    v = (kspo_plan.get("videos", {}) or {}).get(cat) or {}
    title = v.get("title")
    if title:
        return title
    freq_map = (kspo_plan.get("top_per_category", {}) or {}).get(cat) or {}
    if freq_map:
        return list(freq_map.keys())[0]
    return "(CSV ê·¼ê±° ë¶€ì¡±)"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¹´ë“œ í¬ë§·í„°(ìµœì¢… ì–‘ì‹ ê°•ì œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _format_fitt_card(
    *,
    name: str,
    freq: str,
    inten: str,
    time_: str,
    type_text: str,
    video_title: str,
    rule_or_caution: str,
    csv_id: str = ""
) -> str:
    lines = [
        "ì¢…ëª©",
        f"{name}",
        "ë¹ˆë„(F)",
        f"{freq}",
        "ê°•ë„(I)",
        f"{inten}",
        "ì‹œê°„(T)",
        f"{time_}",
        "ìœ í˜•(T)",
        f"{type_text}",
        f"(ëŒ€í‘œì˜ìƒ: {video_title})",
        "ì§„í–‰ê·œì¹™Â·ì£¼ì˜",
        f"{rule_or_caution}",
        f"ğŸ¬ {video_title}",
    ]
    if str(csv_id).strip():
        lines.append(f"CSV:{csv_id}")
    return "\n".join(lines).strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM ì‘ë‹µ íŒŒì„œ(ì½œë¡ /ê°œí–‰ ë‘˜ ë‹¤ í—ˆìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _grab_after(label_pat: str, block: str) -> str:
    m = re.search(rf"{label_pat}\s*\n\s*(.+)", block)
    if m: return m.group(1).strip()
    m = re.search(rf"{label_pat}\s*:\s*(.+)", block)
    return m.group(1).strip() if m else ""

def _csv_from(block: str) -> str:
    m = re.search(r"\[CSV:(\d+)\]", block)
    return m.group(1) if m else ""

def _cut(ans: str, start_pat: str, end_pats: List[str]) -> str:
    m = re.search(start_pat, ans)
    if not m: return ""
    s = m.start()
    ends = []
    for p in end_pats:
        mm = re.search(p, ans[s+1:])
        if mm: ends.append(s + 1 + mm.start())
    e = min(ends) if ends else len(ans)
    return ans[s:e].strip()

def _split_main_sections(ans: str) -> Tuple[str, str, str]:
    a = _cut(ans, r"\b1\)\s*ìœ ì‚°ì†Œ\(ì‹¬í\)", [r"\n2\)\s*ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥", r"\n3\)\s*ìœ ì—°ì„±", r"\n### "])
    s = _cut(ans, r"\b2\)\s*ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥", [r"\n3\)\s*ìœ ì—°ì„±", r"\n### "])
    f = _cut(ans, r"\b3\)\s*ìœ ì—°ì„±", [r"\n### "])
    return a or "", s or "", f or ""

def _extract_extra_blocks(ans: str) -> Dict[str, str]:
    b1 = _cut(ans, r"###\s*ì„¤ë¬¸\s*1Â·4\s*ê¸°ë°˜\s*ì£¼ì˜ì‚¬í•­\s*\(ACSM ê·¼ê±°\)", ["\n### "])
    b2 = _cut(ans, r"###\s*ì„¤ë¬¸\s*2\s*ê¸°ë°˜\s*ìƒë‹´/ë™ê¸°ë¶€ì—¬\s*\(ACSM ê·¼ê±°\)", ["\n### "])
    b3 = _cut(ans, r"###\s*ì„¤ë¬¸\s*3\s*ê¸°ë°˜\s*ë‹¬ì„±\s*ì „ëµ", ["\n### "])
    return {
        "survey14_caution": b1.strip(),
        "survey2_motivation": b2.strip(),
        "survey3_action": b3.strip(),
    }

def _cards_from_llm(answer: str, kspo_plan: Dict[str, Any], csv_neighbors: List[Dict[str, Any]]) -> str:
    a_blk, s_blk, f_blk = _split_main_sections(answer)

    # ìœ ì‚°ì†Œ
    a_name = _grab_after(r"ì¢…ëª©", a_blk)
    a_freq = _grab_after(r"ë¹ˆë„\(F\)", a_blk) or "ì£¼ 3íšŒ"
    a_intn = _grab_after(r"ê°•ë„\(I\)", a_blk) or "ì‹¬ë°•ìˆ˜ 120~150 bpm ë˜ëŠ” RPE 12-15"
    a_time = _grab_after(r"ì‹œê°„\(T\)", a_blk) or "íšŒë‹¹ 30ë¶„"
    a_type = _grab_after(r"ìœ í˜•\(T\)", a_blk) or _type_line_for_category("ì‹¬íì§€êµ¬ë ¥", kspo_plan)
    a_rule = _grab_after(r"ì§„í–‰ê·œì¹™Â·ì£¼ì˜", a_blk) or "ìœ ì‚°ì†Œ ì „ ë™ì  ìŠ¤íŠ¸ë ˆì¹­ í¬í•¨, í†µì¦ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨."
    a_csv  = _csv_from(a_blk) or str((csv_neighbors or [{}])[0].get("row_id") or "")
    v_a = (kspo_plan.get("videos", {}) or {}).get("ì‹¬íì§€êµ¬ë ¥") or {}
    a_video = v_a.get("title") or _head_line_for_category("ì‹¬íì§€êµ¬ë ¥", kspo_plan)

    # ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥
    s_name = _grab_after(r"ì¢…ëª©", s_blk)
    s_freq = _grab_after(r"ë¹ˆë„\(F\)", s_blk) or "ì£¼ 2~3íšŒ(ë¹„ì—°ì†ì¼)"
    s_intn = _grab_after(r"ê°•ë„\(I\)", s_blk) or "1RM 60% ë˜ëŠ” 10~15íšŒ ê°€ëŠ¥ ì¤‘ëŸ‰"
    s_time = _grab_after(r"ì‹œê°„\(T\)", s_blk) or "íšŒë‹¹ 20~40ë¶„"
    s_type = _grab_after(r"ìœ í˜•\(T\)", s_blk) or _type_line_for_category("ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥", kspo_plan)
    s_rule = _grab_after(r"ì£¼ì˜/ëŒ€ì•ˆ", s_blk) or "í†µì¦ ì—†ëŠ” ë²”ìœ„, ì„¸íŠ¸ ê°„ 60~90ì´ˆ íœ´ì‹."
    s_csv  = _csv_from(s_blk) or str((csv_neighbors or [{}])[0].get("row_id") or "")
    v_s = (kspo_plan.get("videos", {}) or {}).get("ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥") or {}
    s_video = v_s.get("title") or _head_line_for_category("ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥", kspo_plan)

    # ìœ ì—°ì„±
    f_name = _grab_after(r"ì¢…ëª©", f_blk)
    f_freq = _grab_after(r"ë¹ˆë„\(F\)", f_blk) or "ì£¼ 3~5íšŒ"
    f_intn = _grab_after(r"ê°•ë„\(I\)", f_blk) or "í†µì¦ ì—†ëŠ” ë²”ìœ„ì—ì„œ ì²œì²œíˆ ì‹ ì¥"
    f_time = _grab_after(r"ì‹œê°„\(T\)", f_blk) or "ë¶€ìœ„ë‹¹ 20~30ì´ˆÃ—2~4ì„¸íŠ¸"
    f_type = _grab_after(r"ìœ í˜•\(T\)", f_blk) or _type_line_for_category("ìœ ì—°ì„±", kspo_plan)
    f_rule = "í˜¸í¡ì„ ì°¸ì§€ ë§ê³  ë°˜ë™ ì—†ì´ ìœ ì§€."
    f_csv  = _csv_from(f_blk) or str((csv_neighbors or [{}])[0].get("row_id") or "")
    v_f = (kspo_plan.get("videos", {}) or {}).get("ìœ ì—°ì„±") or {}
    f_video = v_f.get("title") or _head_line_for_category("ìœ ì—°ì„±", kspo_plan)

    card_aero = _format_fitt_card(
        name=a_name or _head_line_for_category("ì‹¬íì§€êµ¬ë ¥", kspo_plan),
        freq=a_freq, inten=a_intn, time_=a_time,
        type_text=a_type, video_title=a_video,
        rule_or_caution=a_rule, csv_id=a_csv
    )
    card_strn = _format_fitt_card(
        name=s_name or _head_line_for_category("ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥", kspo_plan),
        freq=s_freq, inten=s_intn, time_=s_time,
        type_text=s_type, video_title=s_video,
        rule_or_caution=s_rule, csv_id=s_csv
    )
    card_flex = _format_fitt_card(
        name=f_name or _head_line_for_category("ìœ ì—°ì„±", kspo_plan),
        freq=f_freq, inten=f_intn, time_=f_time,
        type_text=f_type, video_title=f_video,
        rule_or_caution=f_rule, csv_id=f_csv
    )
    return "\n\n".join([card_aero, card_strn, card_flex]) + "\n"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ OpenAI í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_openai(system_prompt: str, user_prompt: str) -> str:
    try:
        client = _get_openai_client()
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.6,
            max_tokens=1200,
        )
        return (completion.choices[0].message.content or "").strip()
    except Exception as e:
        return f"âš ï¸ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def _fmt_allowlist(top_per_category: Dict[str, Dict[str,int]], videos: Dict[str, Any], n:int=5) -> str:
    out = ["### í—ˆìš© ì¢…ëª©/ëŒ€í‘œ ì˜ìƒ (ì¹´í…Œê³ ë¦¬ë³„)"]
    for cat in VALID_CATS:
        freq_map = top_per_category.get(cat) or {}
        names_sorted = sorted(freq_map.items(), key=lambda kv: (-kv[1], kv[0]))[:n]
        names = [f"{i+1}. {name} (x{cnt})" for i, (name, cnt) in enumerate(names_sorted)]
        v = (videos or {}).get(cat) or {}
        vline = f"- ëŒ€í‘œì˜ìƒ: {v.get('title','(ì—†ìŒ)')} (YouTube: {v.get('youtube_url','')})"
        out.append(f"\n**{cat}**\n- í—ˆìš© ì¢…ëª© Top{n}: " + (", ".join(names) if names else "(ì—†ìŒ)") + f"\n{vline}")
    return "\n".join(out)

def _fmt_csv_block(csv_neighbors: List[Dict[str, Any]]) -> str:
    lines = []
    for n in (csv_neighbors or []):
        score = _score_of(n)
        lines.append(
            f"[CSV:{n.get('row_id')}] (ìœ ì‚¬ë„ {score:.2f}) "
            f"ì„±ë³„ {n.get('sex')} Â· ë‚˜ì´ {n.get('age')} Â· BMI {n.get('bmi')} Â· "
            f"ì‹¯ì—… {n.get('situp_reps')} Â· ì¢Œì „êµ´ {n.get('reach_cm')}cm Â· VOâ‚‚max {n.get('vo2max')}\n"
            f"ì²˜ë°© ìš”ì•½: {(n.get('prescription_text') or '').strip()}"
        )
    return "\n\n".join(lines) if lines else "(ìœ ì‚¬ ì‚¬ë¡€ ì—†ìŒ)"

def _fmt_acsm_block(cands: List[Dict[str, Any]]) -> str:
    if not cands:
        return "(ACSM6 ê·¼ê±° ì—†ìŒ)"
    lines = []
    for it in cands:
        did = it.get("doc_id") or "ACSM6:UNK"
        title = it.get("title") or "(ì œëª© ì—†ìŒ)"
        excerpt = (it.get("excerpt") or "").strip()
        if len(excerpt) > 240:
            excerpt = excerpt[:240].rstrip() + "â€¦"
        lines.append(f"[ACSM6:{did}] {title}\n- í•µì‹¬: {excerpt}")
    return "\n\n".join(lines)

def build_kspo_prompt(payload: Dict[str, Any],
                      csv_neighbors: List[Dict[str, Any]],
                      kspo_plan: Dict[str, Any],
                      acsm_cands: List[Dict[str, Any]]) -> Dict[str, str]:
    u = payload.get("user", {}) or {}
    m = payload.get("measurements", {}) or {}
    surveys = payload.get("surveys", {}) or {}

    allow_md = _fmt_allowlist(kspo_plan.get("top_per_category", {}), kspo_plan.get("videos", {}))
    csv_md   = _fmt_csv_block(csv_neighbors)
    acsm_md  = _fmt_acsm_block(acsm_cands)

    system = (
        "ë‹¹ì‹ ì€ ì„ìƒ ìš´ë™ì „ë¬¸ê°€ì´ì ìš´ë™ì²˜ë°© ì½”ì¹˜ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤. "
        "ì•„ë˜ â€˜ì¶œë ¥ í˜•ì‹â€™ì˜ ì œëª©/ë¼ë²¨/ìˆœì„œ/êµ¬ë‘ì ì„ 1ìë„ ë°”ê¾¸ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì±„ìš°ì„¸ìš”. "
        "ìœ í˜•(T) ìë¦¬í‘œì‹œì(<<TYPE_*>>)ì™€ ì¢…ëª© í—¤ë“œ(<<HEAD_*>>)ëŠ” ê·¸ëŒ€ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤(í›„ì²˜ë¦¬ë¡œ ì¹˜í™˜ë¨). "
        "ëª¨ë“  ê¶Œê³  í•­ëª©ì˜ ê·¼ê±°ëŠ” [CSV:row_id], [ACSM6:doc_id]ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.\n"
        "[ë°ì´í„° ì›ì¹™]\n"
        "- KSPO í—ˆìš© ë¦¬ìŠ¤íŠ¸ ë‚´ ì¢…ëª©/ì˜ìƒë§Œ ì‚¬ìš©.\n"
        "- FITT ìˆ˜ì¹˜ë¥¼ ëª…í™•íˆ ì œì‹œ.\n"
        "- ì•ˆì „ ìµœìš°ì„ : PAR-Q/ë…¸ì‡  ì‹ í˜¸ê°€ ìˆìœ¼ë©´ ì €ê°•ë„/ì ì§„Â·ì¦ìƒ ëª¨ë‹ˆí„°ë§Â·ì˜ë£Œìƒë‹´ ê¶Œê³ .\n"
        "[ì„¤ë¬¸ í•´ì„ ê·œì¹™]\n"
        "- ì„¤ë¬¸1(PAR-Q): Q2=ì˜ˆ(ìš´ë™ ì‹œ í‰í†µ) â†’ ì €ê°•ë„ ì‹œì‘, ì¦ìƒ ëª¨ë‹ˆí„°ë§, ì˜ë£Œí‰ê°€ ê¶Œê³ . "
        "Q5=ì˜ˆ(ê·¼ê³¨ê²© ë¬¸ì œ) â†’ í†µì¦ ìœ ë°œ ë™ì‘ íšŒí”¼Â·ROM ë‚´ ìˆ˜í–‰Â·ì €ì¶©ê²© ëŒ€ì²´. high_risk=true â†’ ì´ˆê¸° 1~2ì£¼ RPE 9~11.\n"
        "- ì„¤ë¬¸4(ë…¸ì‡ ): frailty_flag=true ë˜ëŠ” í”¼ë¡œ/ë³´í–‰ê³¤ë€=ì˜ˆ â†’ ê· í˜•Â·ê¸°ëŠ¥ ì¤‘ì‹¬, ì„¸íŠ¸Â·ì‹œê°„ ì¶•ì†Œ, íœ´ì‹ ì—°ì¥.\n"
        "- ì„¤ë¬¸2(ëª©ì /ì¥ë²½): â€˜ì²´ë ¥ì¸¡ì •(ì±„ìš©ìš©)â€™ì´ë©´ ê²€ì‚¬ ì ìˆ˜ í–¥ìƒ ì§€í–¥(ê¸°ë³¸ê¸°Â·ì•ˆì „Â·ê·œì¹™ì„±). "
        "ì¥ë²½: í¥ë¯¸ë¶€ì¬â†’ê²Œì„í™”/ì±Œë¦°ì§€, íš¨ê³¼ë¶ˆí™•ì‹¤â†’ì£¼ê°„ ì§€í‘œ ì‹œê°í™”(RPEÂ·íœ´ì‹ì‹¬ë°•Â·ì„¸íŠ¸ìˆ˜), ì‹œê°„ë¶€ì¡±â†’10~15ë¶„ ë¸”ë¡, í†µì¦â†’ì €ê°•ë„Â·ëŒ€ì²´ë™ì‘.\n"
        "- ì„¤ë¬¸3(IPAQ): MET ë³€í™˜(ê³ ê°•ë„8.0Â·ì¤‘ê°•ë„4.0Â·ê±·ê¸°3.3)ìœ¼ë¡œ ì£¼ê°„ ì´ëŸ‰ ë¶„ë¥˜(â‰¥3000 ë†’ìŒ/â‰¥600 ì¤‘ê°„/ê·¸ ì™¸ ë‚®ìŒ). "
        "ì•‰ì•„ìˆê¸° â‰¥120ë¶„/ì¼ â†’ 30~45ë¶„ë§ˆë‹¤ 1~2ë¶„ ê¸°ë¦½/ë³´í–‰. ê³ ê°•ë„ ê³¼ë‹¤ ì‹œ ì¤‘ê°•ë„Â·íœ´ì‹ì¼ ë°°ì¹˜.\n"
    )

    user_prompt = (
        "=== ì‚¬ìš©ì ìš”ì•½ ===\n"
        f"ì„±ë³„: {u.get('sex')} | ë‚˜ì´: {u.get('age')}\n"
        f"í‚¤/ì²´ì¤‘/BMI: {u.get('height_cm')}cm / {u.get('weight_kg')}kg / {u.get('bmi')}\n"
        f"ì¸¡ì •ì¹˜: ì‹¯ì—… {m.get('situp_reps')}íšŒ Â· ì¢Œì „êµ´ {m.get('reach_cm')}cm Â· VOâ‚‚max {m.get('step_vo2max')}\n"
        "\n=== í—ˆìš© ë¦¬ìŠ¤íŠ¸(í•„ìˆ˜ ì¤€ìˆ˜; KSPO ë§¤ì¹­ ê²°ê³¼) ===\n" + allow_md +
        "\n\n=== ìœ ì‚¬ ì‚¬ë¡€ ê·¼ê±° Top-K (CSV) ===\n" + csv_md +
        "\n\n=== ACSM6 ê·¼ê±° í›„ë³´ ===\n" + acsm_md +
        "\n\n=== ì„¤ë¬¸ JSON ===\n" + json.dumps(surveys, ensure_ascii=False) +
        "\n\n[ì¶œë ¥ í˜•ì‹]\n"
        "ë§ì¶¤ ìš´ë™ì²˜ë°© (4~6ì£¼)\n"
        "1) ìœ ì‚°ì†Œ(ì‹¬í)\n"
        "ì¢…ëª©: <<HEAD_AERO>>\n"
        "\n"
        "ë¹ˆë„(F): ì£¼ 3íšŒ\n"
        "ê°•ë„(I): ì‹¬ë°•ìˆ˜ XX~YY bpm ë˜ëŠ” RPE XX\n"
        "ì‹œê°„(T): íšŒë‹¹ XXë¶„\n"
        "ìœ í˜•(T): <<TYPE_AERO>>\n"
        "ì§„í–‰ê·œì¹™Â·ì£¼ì˜: â€¦\n"
        "ê·¼ê±°: [CSV:row_id], [ACSM6:doc_id]\n"
        "2) ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥\n"
        "ì¢…ëª©: <<HEAD_STRENGTH>>\n"
        "\n"
        "ë¹ˆë„(F): ì£¼ 2íšŒ\n"
        "ê°•ë„(I): 1RM XX% ë˜ëŠ” X~YíšŒ ê°€ëŠ¥ ì¤‘ëŸ‰\n"
        "ì‹œê°„(T): Xì„¸íŠ¸Ã—YíšŒ, ì„¸íŠ¸ ê°„ ZZì´ˆ\n"
        "ìœ í˜•(T): <<TYPE_STRENGTH>>\n"
        "ì£¼ì˜/ëŒ€ì•ˆ: â€¦\n"
        "ê·¼ê±°: [CSV:row_id], [ACSM6:doc_id]\n"
        "3) ìœ ì—°ì„±\n"
        "ì¢…ëª©: <<HEAD_FLEX>>\n"
        "\n"
        "ë¹ˆë„(F): ì£¼ 4íšŒ\n"
        "ì‹œê°„(T): ë¶€ìœ„ë‹¹ XXì´ˆÃ—Xì„¸íŠ¸\n"
        "ê°•ë„(I): í†µì¦ ì—†ëŠ” ë²”ìœ„\n"
        "ìœ í˜•(T): <<TYPE_FLEX>>\n"
        "ê·¼ê±°: [CSV:row_id], [ACSM6:doc_id]\n"
        "\n"
        "ê·¼ê±° ì¶”ì í‘œ\n"
        "| í•­ëª© | ì„ íƒ ì´ìœ (í•µì‹¬) | CSV | ACSM6 |\n"
        "|---|---|---|---|\n"
        "\n"
        "### ì„¤ë¬¸ 1Â·4 ê¸°ë°˜ ì£¼ì˜ì‚¬í•­ (ACSM ê·¼ê±°)\n"
        "- â€¦\n"
        "\n"
        "### ì„¤ë¬¸ 2 ê¸°ë°˜ ìƒë‹´/ë™ê¸°ë¶€ì—¬ (ACSM ê·¼ê±°)\n"
        "- â€¦\n"
        "\n"
        "### ì„¤ë¬¸ 3 ê¸°ë°˜ ë‹¬ì„± ì „ëµ\n"
        "- â€¦\n"
    )
    return {"system": system, "user": user_prompt}

def generate_prescription_kspo_only(
    payload: Dict[str, Any],
    *,
    top_k: int = 10,
    per_cat: int = 1,
    acsm_top_k: int = 8
) -> Dict[str, Any]:
    u = payload.get("user", {}) or {}
    m = payload.get("measurements", {}) or {}
    csv_neighbors = retrieve_similar_structured(u, m, top_k=top_k, overfetch=top_k*10)

    freq = _extract_names_from_csv_neighbors(csv_neighbors)

    kspo_meta_path = _kspo_meta_path()
    user_age = (payload.get("user") or {}).get("age")
    kspo_plan = prescribe_from_freq_and_kspo(freq, kspo_meta_path, user_age=user_age)

    meta_rows = _load_json_list(_kspo_meta_path())
    user_band = _age_band_from_age(user_age)
    for cat in VALID_CATS:
        v = (kspo_plan.get("videos", {}) or {}).get(cat) or {}
        title = v.get("title") or ""
        if not title:
            continue
        best = _rerank_video_by_age_and_target(
            picked=v, title=title, category=cat,
            user_age_band=user_band, meta_rows=meta_rows,
        )
        if best and best is not v:
            kspo_plan["videos"][cat] = best

    acsm_cands = retrieve_acsm_candidates(payload, top_k=acsm_top_k)

    prompts = build_kspo_prompt(payload, csv_neighbors, kspo_plan, acsm_cands)
    answer = call_openai(prompts["system"], prompts["user"]) or ""

    aero_head = _head_line_for_category("ì‹¬íì§€êµ¬ë ¥", kspo_plan)
    str_head  = _head_line_for_category("ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥", kspo_plan)
    flex_head = _head_line_for_category("ìœ ì—°ì„±", kspo_plan)

    aero_line = _type_line_for_category("ì‹¬íì§€êµ¬ë ¥", kspo_plan)
    str_line  = _type_line_for_category("ê·¼ë ¥/ê·¼ì§€êµ¬ë ¥", kspo_plan)
    flex_line = _type_line_for_category("ìœ ì—°ì„±", kspo_plan)

    answer = (answer
        .replace("<<HEAD_AERO>>", aero_head)
        .replace("<<HEAD_STRENGTH>>", str_head)
        .replace("<<HEAD_FLEX>>", flex_head)
        .replace("<<TYPE_AERO>>", aero_line)
        .replace("<<TYPE_STRENGTH>>", str_line)
        .replace("<<TYPE_FLEX>>", flex_line)
    )

    cards_text = _cards_from_llm(answer, kspo_plan, csv_neighbors)

    extra = _extract_extra_blocks(answer)
    extra_md_parts = []
    if extra.get("survey14_caution"):
        extra_md_parts.append("### ì„¤ë¬¸ 1Â·4 ê¸°ë°˜ ì£¼ì˜ì‚¬í•­ (ACSM ê·¼ê±°)\n" + extra["survey14_caution"].strip())
    if extra.get("survey2_motivation"):
        extra_md_parts.append("### ì„¤ë¬¸ 2 ê¸°ë°˜ ìƒë‹´/ë™ê¸°ë¶€ì—¬ (ACSM ê·¼ê±°)\n" + extra["survey2_motivation"].strip())
    if extra.get("survey3_action"):
        extra_md_parts.append("### ì„¤ë¬¸ 3 ê¸°ë°˜ ë‹¬ì„± ì „ëµ\n" + extra["survey3_action"].strip())
    extra_md = ("\n\n" + "\n\n".join(extra_md_parts)) if extra_md_parts else ""

    def _as_int(x):
        try: return int(float(x))
        except Exception: return None
    def _project_video(v: Optional[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        if not v: return None
        return {
            "title": v.get("title") or "",
            "fitness_category": v.get("fitness_category") or "",
            "tool": v.get("tool") or "",
            "body_part": v.get("body_part") or "",
            "target": v.get("target") or "",
            "disease": v.get("disease") or "",
            "youtube_id": v.get("youtube_id") or "",
            "youtube_url": v.get("youtube_url") or "",
            "thumb_url": v.get("thumb_url") or "",
            "page_no": _as_int(v.get("page_no")),
            "rank_on_page": _as_int(v.get("rank_on_page")),
        }
    videos_projected = {cat: _project_video(kspo_plan.get("videos", {}).get(cat)) for cat in VALID_CATS}

    return {
        "planText": {
            "planText": (cards_text + extra_md).strip(),
            "cardsOnly": cards_text.strip(),
            "surveyBlocks": extra,
            "debug": {
                "query": "csv-kNN â†’ KSPO allow-list + ACSM6 (+age-target rerank)",
                "args": {"top_k": top_k, "per_cat": per_cat, "acsm_top_k": acsm_top_k},
                "retrieved_csv": [
                    {"score": _score_of(n), "meta": {"row_id": n.get("row_id")}}
                    for n in (csv_neighbors or [])
                ],
                "kspo_top_per_category": kspo_plan.get("top_per_category", {}),
                "kspo_videos": videos_projected,
                "acsm_candidates": [
                    {"doc_id": c.get("doc_id"), "title": c.get("title")}
                    for c in (acsm_cands or [])
                ],
                "rag_status": rag_status(),
            },
        },
        "case_refs": csv_neighbors,
        "kspo": {
            "top_per_category": kspo_plan.get("top_per_category", {}),
            "videos": videos_projected,
            "unknown_items": kspo_plan.get("unknown_items", []),
            "categorized": kspo_plan.get("categorized", {}),
            "freq": kspo_plan.get("freq", {}),
        },
        "acsm6": {
            "candidates": acsm_cands or [],
        },
    }

# ë‚´ë¶€: ë©”íƒ€ ë¡œë“œ(JSON list ì§€ì›)
def _load_json_list(path: str) -> List[Dict[str, Any]]:
    if not os.path.exists(path):
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, list):
            return data
        return data.get("docs") or data.get("items") or []
    except Exception:
        return []

__all__ = ["generate_prescription_kspo_only", "rag_status", "_get_openai_client"]
